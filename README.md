# mount

this is a repository recording papars, lectures or other knowledge I learned (starting from 19, Nov 11)

## papers
19, Nov 12
* [Orthogonal Gradient Descent for Continual Learning](https://arxiv.org/abs/1910.07104)
* [Task2Vec: Task Embedding for Meta-Learning](https://arxiv.org/abs/1902.03545)
* [Progressive Neural Networks](https://arxiv.org/abs/1606.04671)
* [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635)
* [Rethinking the Value of Network Pruning](https://arxiv.org/abs/1810.05270)
* [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)
19, Nov 18
* [Gradient-based Hyperparameter Optimization through Reversible Learning](https://arxiv.org/abs/1502.03492)
* [Scalable Bayesian Optimization Using Deep Neural Networks](https://arxiv.org/abs/1502.05700)
* [TADAM: Task dependent adaptive metric for improved few-shot learning](https://arxiv.org/abs/1805.10123)
* [Meta-Learning with Differentiable Convex Optimization](https://arxiv.org/abs/1904.03758)
* [Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples](https://arxiv.org/abs/1903.03096)
* [Meta-Learning for Semi-Supervised Few-Shot Classification](https://arxiv.org/abs/1803.00676)
* [Semi-supervised Domain Adaptation via Minimax Entropy](https://arxiv.org/abs/1904.06487)
* [Adversarial Dropout Regularization](https://arxiv.org/abs/1711.01575)
* [Maximum Classifier Discrepancy for Unsupervised Domain Adaptation](https://arxiv.org/abs/1712.02560)

## lectures
19, Nov 11
* Next Step of Machine Learning (Hung-yi Lee, 2019)
* [ICCV 2019, Visual Learning with Limited Labeled Data](https://sites.google.com/view/learning-with-limited-data)

