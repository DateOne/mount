# A General and Adaptive Robust Loss Function
## Pros
This paper introduces a more general loss function that can be adapted to several other loss 
functions with a parameter measuring robustness, which, according to the paper, can be 
learned (?). This paper also includes multiple loss functions this loss function can be 
adapted to and multiple common probability density functions the negative log-likelihood of
this loss function can be adapted to.
## Others
1. in a certain sense, robustness is about the degree of a model being influenced by outliers 
than inliers.
2. in this paper, the author explains different loss, focusing on their capability on handling
outliers, which inspires me that if I want to devise a model that can learn multiple distritions
(like an ensemble), diversity between domains (just like outliers) must be emphasized (by loss 
or by other tricks).
3. this paper explains losses in terms of average, the theory of which renders me much thoughts
about understanding deep learning process visually.
4. this paper's discussion about the neccessity of NLL is wonderful (the trade-off thing).
