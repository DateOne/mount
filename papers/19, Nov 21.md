# A General and Adaptive Robust Loss Function
## Pros
This paper introduces a more general loss function that can be adapted to several other loss 
functions with a parameter measuring robustness, which, according to the paper, can be 
learned (?). This paper also includes multiple loss functions this loss function can be 
adapted to and multiple common probability density functions the negative log-likelihood of
this loss function can be adapted to.
## Others
* in a certain sense, robustness is about the degree of a model being influenced by outliers 
than inliers.
* in this paper, the author explains different loss, focusing on their capability on handling
outliers, which inspires me that if I want to devise a model that can learn multiple distritions
(like an ensemble), diversity between domains (just like outliers) must be emphasized (by loss 
or by other tricks).
* this paper explains losses in terms of average, the theory of which renders me much thoughts
about understanding deep learning process visually.
* this paper's discussion about the neccessity of NLL is wonderful (the trade-off thing).
# FiLM: Visual Reasoning with a General Conditioning Layer
## Pros
This paper presents a FiLM model that specifies in a neural network learning activation (of 
each layer) manipulating parameters (in this specific task of visual reasoning, affine 
transformation parameters).
## Others
* The reason why affine transformation works might owes to the natural of the specific questions
in this visual reasoning dataset (colors, numbers or others). We could consider use other 
transformation manipulation parameters to learn dynamic structures for few-shot learning.
* visual reasoning is a very insteresting task. I want to learn more!
# Rapid Adaptation with Conditionally Shifted Neurons
## Pros
This paper improves MetaNet with conditional shifted neurons (didn't expect the task to be 
meta-learning).
## Cons
Too simple.
## Others
1. I should dig deeper into MetaNet. The fast weight seems to be fun.
2. Quick adaptation to tasks do have neuralscientific support!
